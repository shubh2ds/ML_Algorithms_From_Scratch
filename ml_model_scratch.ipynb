{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear  Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LinearRegression:\n",
    "    def __init__(self, lr=0.01 , iteration = 100):\n",
    "        self.lr = lr \n",
    "        self.iteration = iteration\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        n_sample, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        for  _ in range(self.iteration):\n",
    "            y_pred = np.dot(X , self.weights) + self.bias\n",
    "\n",
    "            # MSE = (1/n_sample) * np.sum( (y - ypred)**2 )\n",
    "            dw = (1/n_sample) * np.dot(X.T , (y_pred - y))  \n",
    "            db = (1/n_sample) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X , self.weights) + self.bias\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,3,4,5,6,7,8,9]).reshape(-1,1)\n",
    "y = np.array([100,200,300,400,500,600,700,800,900])\n",
    "model = LinearRegression(lr=0.01 , iteration = 1000)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.66861135970251"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,lr=0.01,iteration=100):\n",
    "        self.lr = lr\n",
    "        self.iteration = iteration\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n_sample, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.iteration):\n",
    "\n",
    "            y_pred = self.sigmoid(np.dot(X , self.weights) + self.bias)\n",
    "            # MSE = (1/n_sample)*np.mean((y-y_pred)**2)\n",
    "            dw = (1/n_sample) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/n_sample) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights = self.weights - self.lr*dw\n",
    "            self.bias = self.bias - self.lr*db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.sigmoid(np.dot(X , self.weights) + self.bias)\n",
    "        y_class = [1 if prob>=0.5 else 0 for prob in y_pred]\n",
    "\n",
    "        return y_pred, y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[10,20], [30,60],[40,80],[40,100],  [10,5],[40,20],[60,30],[100,10]])\n",
    "y = np.array([0,0,0,0, 1,1,1,1])\n",
    "\n",
    "model = LogisticRegression(lr=0.01,iteration=100)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.41125270e-02, 4.97062666e-04, 3.91973652e-05, 1.44284607e-07,\n",
       "        8.42678486e-01, 9.98729390e-01, 9.99954273e-01, 1.00000000e+00]),\n",
       " [0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[10,20], [30,60],[40,80],[40,100],  [10,5],[40,20],[60,30],[100,10]])\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def eucledian(self,a,b):\n",
    "        return np.sqrt( np.sum( (a-b)**2) )\n",
    "    def predict(self,X):\n",
    "\n",
    "        predictions = [ self.predict_(test_point) for test_point in X]\n",
    "        return predictions\n",
    "\n",
    "    def predict_(self, x):\n",
    "        # distances\n",
    "        distances = [ self.eucledian(x, x_train) for x_train in self.X_train]\n",
    "        # k nearest\n",
    "        nearest_idx = np.argsort(distances)[:self.k]\n",
    "        # majority vote\n",
    "        nearest_class = [self.y_train[idx] for idx in nearest_idx]\n",
    "        majority_vote = Counter(nearest_class).most_common()\n",
    "\n",
    "        return [majority_vote[0][0], majority_vote[0][1], majority_vote[0][1]/self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[10,20], [30,60],[40,80],[40,100],  [10,5],[40,20],[60,30],[100,10]])\n",
    "y = np.array([0,0,0,0, 1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN(k=5)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 0.6],\n",
       " [0, 3, 0.6],\n",
       " [0, 3, 0.6],\n",
       " [0, 3, 0.6],\n",
       " [1, 3, 0.6],\n",
       " [1, 3, 0.6],\n",
       " [1, 3, 0.6],\n",
       " [1, 4, 0.8]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[10,20], [30,60],[40,80],[40,100],  [10,5],[40,20],[60,30],[100,10]])\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
